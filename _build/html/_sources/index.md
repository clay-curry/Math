# Introduction

These notes strive to provide a compact, self-contained introduction to some fascinating recent developments at the interface of group representation theory, non-commutative harmonic analysis (or Fourier Analysis), and artificial neural networks. After briefly introducing some theory, we will survey influential papers and distill core principles fueling an increasing trend to incorporte non-commutative algebraic structures in deep learning architectures, inducing crucial inductive biases for robust, data-efficient machine learning.  Importantly, these notes present a unified mathematical description of fundamental methodological developments in the construction of neural networks.

These notes attempt to provide an accessible introduction to abstract mathematics, and state-of-the-art engineering methods making up the science and art of deep learning of today. Being written for a general (mathematically-inclined) computer science audience, these notes will equip the dedicated follower with a mathematically rigorous toolkit for that can be immediately used in construction of new neural architectures. The necessary prerequisites for success in this survey are a basic understanding of linear algebra, a basic understanding of calculus, some familiarity with the Python language and its machine learning libraries, and a unfettered thirst to contribute to the greatest story ever told.

I hope you find these notes to be a worthwile and accessible vantage of this remarkable journey to understand and engineer intelligence.

<p>
<div style="text-align: right">Clay Curry</div>
<div style="text-align: right">Norman, OK, USA</div>
<div style="text-align: right">Feb 2023</div>
</p>

```{tableofcontents}
```
